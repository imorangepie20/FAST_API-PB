import os
import glob
import json
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Any

from fastapi import FastAPI, APIRouter, HTTPException
from pydantic import BaseModel
from sqlalchemy import text
from scipy.spatial.distance import cdist
from catboost import CatBoostRegressor, Pool
from sklearn.model_selection import train_test_split

# [ì£¼ì˜] ì´ ë¶€ë¶„ì€ ì‹¤ì œ í”„ë¡œì íŠ¸ í™˜ê²½ì— ë§ê²Œ DB ì—”ì§„ ì„¤ì •ì„ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.
# ë§Œì•½ ë³„ë„ì˜ database.pyê°€ ìˆë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í’€ê³  ì‚¬ìš©í•˜ì„¸ìš”.
# from app.database import engine 
# ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¥¼ ìœ„í•´ engine ê°ì²´ê°€ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜ ë¡œì»¬ ì„¤ì •ì„ ì°¸ì¡°í•©ë‹ˆë‹¤.

app = FastAPI(title="Music Recommendation API")

# --- [1. Pydantic Models] ---
class AnalysisRequest(BaseModel):
    userid: str

class AnalysisResponse(BaseModel):
    status: str
    message: str

# --- [2. Configuration & Globals] ---
# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
# ê¸°ì¡´ ê²½ë¡œ ë¡œì§ì„ ìœ ì§€í•˜ë˜, í†µí•© íŒŒì¼ ìœ„ì¹˜ì— ë”°ë¼ BASE_DIR ì¡°ì • í•„ìš”
BASE_DIR = os.path.dirname(CURRENT_DIR) 

MODEL_DIR = os.path.join(BASE_DIR, 'model')
DATASET_PATH = os.path.join(BASE_DIR, 'dataset', 'dataset.csv')

# ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
model = CatBoostRegressor()
df = None
features = ['artists', 'album_name', 'track_genre']
target_columns = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness']

# --- [3. Internal Functions] ---

def get_latest_model_path(user_id):
    search_pattern = os.path.join(MODEL_DIR, f"recommender_U{user_id}_*.cbm")
    model_files = glob.glob(search_pattern)
    if not model_files:
        return None
    latest_model = max(model_files, key=os.path.getmtime)
    return latest_model

def generate_new_model_path(user_id, playlist_title=""):
    date_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_title = "".join(x for x in playlist_title if x.isalnum())[:10]
    return os.path.join(MODEL_DIR, f"recommender_U{user_id}_{safe_title}_{date_str}.cbm")

def train_user_model(user_id, playlist_title, temp_df):
    global model
    print(f"ğŸš€ [Training] ìœ ì € {user_id} ì „ìš© ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    
    train_df, eval_df = train_test_split(temp_df, test_size=0.3, random_state=42)
    train_pool = Pool(data=train_df[features], label=train_df[target_columns], cat_features=features)
    eval_pool = Pool(data=eval_df[features], label=eval_df[target_columns], cat_features=features)
    
    new_model = CatBoostRegressor(iterations=500, learning_rate=0.05, depth=6, loss_function='MultiRMSE', random_seed=42, verbose=False)
    new_model.fit(train_pool, eval_set=eval_pool, early_stopping_rounds=50)
    
    new_path = generate_new_model_path(user_id, playlist_title)
    os.makedirs(MODEL_DIR, exist_ok=True)
    new_model.save_model(new_path)
    return new_model

def save_gms_to_db(user_id, recommended_tracks, engine):
    print(f"ğŸ’¾ ìœ ì € {user_id}ì˜ GMS í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
    try:
        with engine.begin() as conn:
            conn.execute(text("""
                INSERT INTO playlists (user_id, title, description, space_type, status_flag, source_type)
                VALUES (:uid, 'AI ì¶”ì²œ ë¦¬ìŠ¤íŠ¸', 'ìµœì‹  ëª¨ë¸ ê¸°ë°˜ ì¶”ì²œ', 'GMS', 'PTP', 'System')
            """), {"uid": user_id})
            gms_id = conn.execute(text("SELECT LAST_INSERT_ID()")).scalar()
            
            for _, row in recommended_tracks.iterrows():
                metadata = json.dumps({"kaggle_id": row.get('track_id', ''), "genre": row.get('track_genre', 'unknown')})
                conn.execute(text("""
                    INSERT INTO tracks (title, artist, album, external_metadata)
                    VALUES (:title, :artist, :album, :meta)
                """), {
                    "title": row['track_name'], "artist": row['artists'], 
                    "album": row['album_name'], "meta": metadata
                })
                tid = conn.execute(text("SELECT LAST_INSERT_ID()")).scalar()
                conn.execute(text("""
                    INSERT INTO playlist_tracks (playlist_id, track_id)
                    VALUES (:pid, :tid)
                """), {"pid": gms_id, "tid": tid})
        return True
    except Exception as e:
        print(f"ğŸ”¥ GMS ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

# --- [4. Core Service Logic] ---

def process_analysis(userid: str):
    global model, df
    # ì™¸ë¶€ app.databaseì—ì„œ engineì„ ê°€ì ¸ì˜¨ë‹¤ê³  ê°€ì •
    from app.database import engine 
    
    uid = int(userid)
    try:
        if df is None:
            if not os.path.exists(DATASET_PATH):
                return f"ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATASET_PATH}"
            df = pd.read_csv(DATASET_PATH)
            for col in features: df[col] = df[col].fillna('unknown').astype(str)
            df[target_columns] = df[target_columns].fillna(0)

        latest_model_path = get_latest_model_path(uid)
        
        with engine.connect() as conn:
            query = text("""
                SELECT p.title, t.title as track_title, t.artist, t.album, t.external_metadata
                FROM tracks t
                JOIN playlist_tracks pt ON t.track_id = pt.track_id
                JOIN playlists p ON pt.playlist_id = p.playlist_id
                WHERE p.user_id = :uid AND p.space_type = 'PMS'
            """)
            result = conn.execute(query, {"uid": uid}).fetchall()
            
            if not result:
                return "ë¶„ì„í•  PMS ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            pms_tracks = pd.DataFrame(result)
            playlist_title = pms_tracks['title'].iloc[0]

        if latest_model_path:
            model.load_model(latest_model_path)
        else:
            model = train_user_model(uid, playlist_title, df)

        def safe_get_genre(meta):
            try: return json.loads(meta).get('genre', 'unknown')
            except: return 'unknown'

        pms_tracks['track_genre'] = pms_tracks['external_metadata'].apply(safe_get_genre)
        pms_input = pms_tracks[['artist', 'album', 'track_genre']].fillna('unknown').astype(str)
        pms_input.columns = features 

        pms_predictions = model.predict(pms_input)
        user_taste_vector = pms_predictions.mean(axis=0)

        ems_features_input = df[features].fillna('unknown').astype(str)
        ems_predictions = model.predict(ems_features_input)

        distances = cdist([user_taste_vector], ems_predictions, metric='euclidean')[0]
        top_indices = np.argsort(distances)[:50]
        recommended_tracks = df.iloc[top_indices].copy()

        if save_gms_to_db(uid, recommended_tracks, engine):
            model_info = os.path.basename(latest_model_path) if latest_model_path else "ì‹ ê·œ ìƒì„±"
            return f"ìœ ì € {uid} ë¶„ì„ ë° GMS ìƒì„± ì™„ë£Œ! (ì‚¬ìš© ëª¨ë¸: {model_info})"
        else:
            return "GMS ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    except Exception as e:
        return f"ì—ëŸ¬ ë°œìƒ: {str(e)}"

# --- [5. API Router] ---
router = APIRouter(tags=["Analysis"])

@router.post("/analyze", response_model=AnalysisResponse, summary="ë¶„ì„ ìš”ì²­ ì²˜ë¦¬")
async def analyze_data(request: AnalysisRequest):
    result_message = process_analysis(request.userid)
    
    if "ì—ëŸ¬" in result_message or "ì—†ìŠµë‹ˆë‹¤" in result_message:
        return {"status": "error", "message": result_message}
        
    return {
        "status": "success",
        "message": result_message
    }

app.include_router(router)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)